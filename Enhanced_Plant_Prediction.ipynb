{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enhanced Plant Prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igorlauxen/local_grape_health/blob/main/Enhanced_Plant_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLwYHrz-dRVE"
      },
      "source": [
        "Para conectar kaggle e google driver seguir o tutorial do [Medium: How to fetch kaggle datasets into google colab](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTHHHE-_dItB",
        "outputId": "0edf4e9d-c5e7-4feb-b1f6-4975a1914d77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf6rhWmldnTZ"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYXaxqjydxSB",
        "outputId": "36a7daf2-8253-4de7-ce58-14792489d38c"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/kaggle\n",
        "\n",
        "#changing the working directory\n",
        "%cd /content/gdrive/MyDrive/kaggle\n",
        "#Check the present working directory using pwd command\n",
        "\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ignore_folder  kaggle.json  label_transform.pkl  plantvillage  PlantVillage\n",
            "/content/gdrive/MyDrive/kaggle\n",
            "ignore_folder  kaggle.json  label_transform.pkl  plantvillage  PlantVillage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp5OD19Neapc",
        "outputId": "13fdf515-f108-4acc-f5e8-e1a9bf752eed"
      },
      "source": [
        "# só execute comando abaixo caso no seu google drie não tenha sido baixado as plantas ainda\n",
        "#!kaggle datasets download -d emmarex/plantdisease"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading plantdisease.zip to /content/gdrive/My Drive/kaggle\n",
            "100% 656M/658M [00:22<00:00, 36.3MB/s]\n",
            "100% 658M/658M [00:22<00:00, 30.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YbqMIPifAE5"
      },
      "source": [
        "# mesmo que passo anterior, caso há tenha sido executado uma vez, nao precisa ocorrer de novo\n",
        "#unzipping the zip files and deleting the zip files\n",
        "#!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_FT_-lCeX3j"
      },
      "source": [
        "Esse notebook baseia sua implementação em [Plant Disease Detection using Keras](https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/data)\n",
        "\n",
        "Dataset utilizado é [Plant Village Disease](https://www.kaggle.com/emmarex/plantdisease)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrIsRqgGfZyr"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.optimizers import Adam precisa importar depois como keras.optimizers.Adam segundo https://keras.io/api/optimizers/\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScqkjUCNfxkr"
      },
      "source": [
        "EPOCHS = 25\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "default_image_size = tuple((256, 256))\n",
        "image_size = 0\n",
        "# NOTA: essa pasta pode variar de location depdendo de onde der a *cd* anteriormente\n",
        "directory_root = 'plantvillage/'\n",
        "width=256\n",
        "height=256\n",
        "# depth 3 significa considerar RGB\n",
        "depth=3"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCu4veCRMa6b",
        "outputId": "b8e1dcbe-f1e9-4823-998c-c3f320ec5bc2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6lVpbDMf0zM"
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YyOYSDRf4CU",
        "outputId": "9814a0e7-6956-4842-c94f-ee4bb5321e70"
      },
      "source": [
        "# o processamento abaixo levar alguns minutos (~15)\n",
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        print(f\"[INFO] The plant folder is {plant_folder} ...\")\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        print(f\"[INFO] The plant disease folder list is {plant_disease_folder_list} ...\")\n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            print(f\"[INFO] The disease folder is {disease_folder} ...\")\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "            if disease_folder == \"Tomato_Spider_mites_Two_spotted_spider_mite\":\n",
        "                print(f\"[INFO] Folder {disease_folder} has been ignored ...\")\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] The plant folder is PlantVillage ...\n",
            "[INFO] The plant disease folder list is ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'] ...\n",
            "[INFO] The disease folder is Pepper__bell___Bacterial_spot ...\n",
            "[INFO] The disease folder is Pepper__bell___healthy ...\n",
            "[INFO] The disease folder is Potato___Early_blight ...\n",
            "[INFO] The disease folder is Potato___Late_blight ...\n",
            "[INFO] The disease folder is Potato___healthy ...\n",
            "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
            "[INFO] Processing Pepper__bell___healthy ...\n",
            "[INFO] Processing Potato___Early_blight ...\n",
            "[INFO] Processing Potato___Late_blight ...\n",
            "[INFO] Processing Potato___healthy ...\n",
            "[INFO] Image loading completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J69QxwAJ7rt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcs7yDxgWcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea82292-1b16-416f-9016-e0c51a4c5363"
      },
      "source": [
        "image_size = len(image_list)\n",
        "print(\"image size is \", image_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size is  952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yA09_KSgYq6"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5UpmYFxgbBI",
        "outputId": "105d8fc4-0161-438b-dc43-36612e15dd14"
      },
      "source": [
        "print(label_binarizer.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pepper__bell___Bacterial_spot' 'Pepper__bell___healthy'\n",
            " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLXO0ajehNPs"
      },
      "source": [
        "# mudado de np.float16 para np.float32\n",
        "# devido a exception no modelo tcc\n",
        "np_image_list = np.array(image_list, dtype=np.float32) / 225.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRT_HAoOha7l"
      },
      "source": [
        "print(np_image_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ofTg7FhfJp",
        "outputId": "a87587f5-db19-411f-d8f1-5c246a765e6d"
      },
      "source": [
        "print(\"[INFO] Spliting data to train, test\")\n",
        "# o que faz train_test_split?\n",
        "# r: ele dividi o dataset em dados de treino e validação. \n",
        "# O parametro test_size é de 0 a 1 e é o que define o percentual que vai para validação\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Spliting data to train, test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ks5DYIrhng4"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMpjxXqvhtaG"
      },
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "# tf.keras.layers.Conv2D(filters (32),kernel_size(3,3)\n",
        "# padding pode ser same ou valid. valid: \"valid\" means no padding\n",
        "#   same: results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
        "# inputShape=(256,256,3): alta resolução com cores\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "# What is activation function? an activation function is needed that looks and acts like a linear function, \n",
        "# but is, in fact, a nonlinear function allowing complex relationships in the data to be learned.\n",
        "# What is Relu? Rectified Linear Unit (ReLU)\n",
        "# linear function that will output the input directly if it is positive, otherwise, it will output zero.\n",
        "model.add(Activation(\"relu\"))\n",
        "# Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
        "# The axis that should be normalized (typically the features axis). \n",
        "# For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFJ3OWm4hyoj",
        "outputId": "51c93810-0c59-47d1-bc0a-357714311d1b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 256, 256, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 256, 256, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 85, 85, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 85, 85, 32)        0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 85, 85, 64)        18496     \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 85, 85, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 85, 85, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 85, 85, 64)        36928     \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 85, 85, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 85, 85, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 42, 42, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 42, 42, 64)        0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 42, 42, 128)       73856     \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 42, 42, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 42, 42, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 42, 42, 128)       147584    \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 42, 42, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 42, 42, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 21, 21, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 21, 21, 128)       0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 56448)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              57803776  \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 5125      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,092,421\n",
            "Trainable params: 58,089,541\n",
            "Non-trainable params: 2,880\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p38bRK-jh3ca",
        "outputId": "68565bd2-5298-47ee-cf31-e91aab20b335"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# from keras.optimizers import a\n",
        "opt = keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "8ThVCG99ijBj",
        "outputId": "3d149ed2-19c8-46d8-f12b-f164bffa4001"
      },
      "source": [
        "# cada epoch demora 10 minutos, processo abaixo demora MUITO\n",
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "23/23 [==============================] - 117s 5s/step - loss: 0.7163 - accuracy: 0.6049 - val_loss: 1.5507 - val_accuracy: 0.2408\n",
            "Epoch 2/25\n",
            "23/23 [==============================] - 115s 5s/step - loss: 0.4274 - accuracy: 0.7695 - val_loss: 1.7622 - val_accuracy: 0.3403\n",
            "Epoch 3/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a94baaa9b5e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2028\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "ncCGC9b0D16s",
        "outputId": "5fc9e302-ad7d-4297-d779-8db8553b0c91"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-36d96611e076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgaHv392J89C"
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgLAOKiKAYn"
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] Saving model...\")\n",
        "pickle.dump(model,open('cnn_model.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aA7DUt6NacO"
      },
      "source": [
        "# segundo o artigo utilizado como base, eles utilizaram a métrica 32 - 64  128 camadas\n",
        "# com um dropout de 0.1 \n",
        "# activatio feature ReLU\n",
        "# referencial teorico\n",
        "tcc_model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "# tf.keras.layers.Conv2D(filters (32),kernel_size(3,3)\n",
        "# padding pode ser same ou valid. valid: \"valid\" means no padding\n",
        "#   same: results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
        "# inputShape=(256,256,3): alta resolução com cores\n",
        "tcc_model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "# What is activation function? an activation function is needed that looks and acts like a linear function, \n",
        "# but is, in fact, a nonlinear function allowing complex relationships in the data to be learned.\n",
        "# What is Relu? Rectified Linear Unit (ReLU)\n",
        "# linear function that will output the input directly if it is positive, otherwise, it will output zero.\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "# Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
        "# The axis that should be normalized (typically the features axis). \n",
        "# For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "tcc_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "tcc_model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "tcc_model.add(Dropout(0.25))\n",
        "tcc_model.add(Flatten())\n",
        "tcc_model.add(Dense(1024))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization())\n",
        "tcc_model.add(Dropout(0.5))\n",
        "tcc_model.add(Dense(n_classes))\n",
        "tcc_model.add(Activation(\"softmax\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS2RWRdGTfBP",
        "outputId": "f74cba5b-7dac-45bf-e339-be704d07b94c"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# from keras.optimizers import a\n",
        "opt = keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "tcc_model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctLwr6RJOzNm",
        "outputId": "f82a246e-b1a0-4238-cb20-a75f62417c21"
      },
      "source": [
        "tcc_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256, 256, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 85, 85, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 85, 85, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 85, 85, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 85, 85, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 42, 42, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 42, 42, 128)       73856     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 42, 42, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 42, 42, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 21, 21, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 21, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 56448)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              57803776  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 5125      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,907,141\n",
            "Trainable params: 57,904,645\n",
            "Non-trainable params: 2,496\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FghW2FQTVGvg"
      },
      "source": [
        "tcc_aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubmrSWaTz6aS"
      },
      "source": [
        "# Estrategia\n",
        "\n",
        "segundo o artigo utilizado como base, eles utilizaram as seguintes métricas#\n",
        "\n",
        "1. Camadas: 32 - 64 - 128\n",
        "1. Dropout de 0.1 \n",
        "1. activatio feature ReLU\n",
        "\n",
        "## Resultados previstos antes de refactoring\n",
        "\n",
        "Utilizando a estrutura abaixo\n",
        "\n",
        "```\n",
        "tcc_model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "tcc_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "tcc_model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization(axis=chanDim))\n",
        "tcc_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "tcc_model.add(Dropout(0.25))\n",
        "tcc_model.add(Flatten())\n",
        "tcc_model.add(Dense(1024))\n",
        "tcc_model.add(Activation(\"relu\"))\n",
        "tcc_model.add(BatchNormalization())\n",
        "tcc_model.add(Dropout(0.5))\n",
        "tcc_model.add(Dense(n_classes))\n",
        "tcc_model.add(Activation(\"softmax\"))\n",
        "```\n",
        "\n",
        "O modelo teve uma acurácia alta (90%), porém o val_accuracy (20.94%) baixo nos primeiros 10 ciclos de desenvolvimento, o que significa que esse dataset consegue entender os dados de treino, porém os de validação ele não conseguem interpretar.\n",
        "\n",
        "Após a décima interação, os valores de val_acc sobem para 38%. O que indica que é o modelo esta parcialmente correto, porém precisa de mais interações pra aprendizado.\n",
        "\n",
        "## Referencial\n",
        "\n",
        "Gokulnath B.V., Usha Devi G. Identifying and classifying plant disease using resilient LF-CNN. Publicado em: Elsevier B.V. 29 de março de 2021.\n",
        "\n",
        "# Comparação\n",
        "\n",
        "O modelo empregado por [Tairu Oluwafemi Emmanuel](https://www.kaggle.com/emmarex) em [Plant Disease Detection using Keras](https://www.kaggle.com/emmarex/plant-disease-detection-using-keras/data) apresenta uma camada similar, entretanto, com mais repetições. Por exemplo, o modelo dele adiciona 2 vezes cada camada (32, 64, 128 respectivamente).\n",
        "\n",
        "Assumimos que ele tenha adotado esse comportamento devido a um resultado similar ao que o nosso modelo objeteve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgqxertMOW0c",
        "outputId": "fcef871e-f6fc-4ea0-9b4f-18433f3321eb"
      },
      "source": [
        "# cada epoch demora 10 minutos, processo abaixo demora MUITO\n",
        "tcc_history = tcc_model.fit_generator(\n",
        "    tcc_aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=2\n",
        "    )\n",
        "\n",
        "#history = model.fit_generator(\n",
        "#      aug.flow(x_train, y_train, batch_size=BS),\n",
        "#      steps_per_epoch=len(x_train),\n",
        "#      epochs=EPOCHS,\n",
        "#      validation_data=(x_test, y_test),\n",
        "#      validation_steps=50,\n",
        "#     verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "23/23 - 72s - loss: 0.4730 - accuracy: 0.7421 - val_loss: 3.8184 - val_accuracy: 0.2094 - 72s/epoch - 3s/step\n",
            "Epoch 2/25\n",
            "23/23 - 72s - loss: 0.3642 - accuracy: 0.7805 - val_loss: 5.7287 - val_accuracy: 0.2094 - 72s/epoch - 3s/step\n",
            "Epoch 3/25\n",
            "23/23 - 72s - loss: 0.2844 - accuracy: 0.8057 - val_loss: 8.5087 - val_accuracy: 0.2094 - 72s/epoch - 3s/step\n",
            "Epoch 4/25\n",
            "23/23 - 72s - loss: 0.2109 - accuracy: 0.8642 - val_loss: 11.9388 - val_accuracy: 0.2094 - 72s/epoch - 3s/step\n",
            "Epoch 5/25\n",
            "23/23 - 71s - loss: 0.1709 - accuracy: 0.8848 - val_loss: 12.5831 - val_accuracy: 0.2094 - 71s/epoch - 3s/step\n",
            "Epoch 6/25\n",
            "23/23 - 70s - loss: 0.1320 - accuracy: 0.9191 - val_loss: 13.2390 - val_accuracy: 0.2094 - 70s/epoch - 3s/step\n",
            "Epoch 7/25\n",
            "23/23 - 71s - loss: 0.1480 - accuracy: 0.9026 - val_loss: 12.8050 - val_accuracy: 0.2094 - 71s/epoch - 3s/step\n",
            "Epoch 8/25\n",
            "23/23 - 71s - loss: 0.1221 - accuracy: 0.9177 - val_loss: 6.9502 - val_accuracy: 0.2094 - 71s/epoch - 3s/step\n",
            "Epoch 9/25\n",
            "23/23 - 71s - loss: 0.1191 - accuracy: 0.9246 - val_loss: 5.9179 - val_accuracy: 0.2094 - 71s/epoch - 3s/step\n",
            "Epoch 10/25\n",
            "23/23 - 70s - loss: 0.1192 - accuracy: 0.9163 - val_loss: 5.8667 - val_accuracy: 0.2094 - 70s/epoch - 3s/step\n",
            "Epoch 11/25\n",
            "23/23 - 70s - loss: 0.0924 - accuracy: 0.9424 - val_loss: 3.3131 - val_accuracy: 0.3455 - 70s/epoch - 3s/step\n",
            "Epoch 12/25\n",
            "23/23 - 70s - loss: 0.1173 - accuracy: 0.9218 - val_loss: 2.1567 - val_accuracy: 0.3717 - 70s/epoch - 3s/step\n",
            "Epoch 13/25\n",
            "23/23 - 70s - loss: 0.1128 - accuracy: 0.9122 - val_loss: 2.1633 - val_accuracy: 0.3717 - 70s/epoch - 3s/step\n",
            "Epoch 14/25\n",
            "23/23 - 70s - loss: 0.0791 - accuracy: 0.9561 - val_loss: 1.7880 - val_accuracy: 0.3665 - 70s/epoch - 3s/step\n",
            "Epoch 15/25\n",
            "23/23 - 70s - loss: 0.0755 - accuracy: 0.9547 - val_loss: 1.8440 - val_accuracy: 0.3822 - 70s/epoch - 3s/step\n",
            "Epoch 16/25\n",
            "23/23 - 70s - loss: 0.0652 - accuracy: 0.9643 - val_loss: 1.6815 - val_accuracy: 0.3874 - 70s/epoch - 3s/step\n",
            "Epoch 17/25\n",
            "23/23 - 70s - loss: 0.0705 - accuracy: 0.9438 - val_loss: 2.1747 - val_accuracy: 0.3665 - 70s/epoch - 3s/step\n",
            "Epoch 18/25\n",
            "23/23 - 70s - loss: 0.0574 - accuracy: 0.9602 - val_loss: 2.4308 - val_accuracy: 0.3613 - 70s/epoch - 3s/step\n",
            "Epoch 19/25\n",
            "23/23 - 70s - loss: 0.0519 - accuracy: 0.9671 - val_loss: 1.7031 - val_accuracy: 0.3822 - 70s/epoch - 3s/step\n",
            "Epoch 20/25\n",
            "23/23 - 70s - loss: 0.0531 - accuracy: 0.9698 - val_loss: 1.2064 - val_accuracy: 0.4188 - 70s/epoch - 3s/step\n",
            "Epoch 21/25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxmM-iclO7AO"
      },
      "source": [
        "acc = tcc_history.history['acc']\n",
        "val_acc = tcc_history.history['val_acc']\n",
        "loss = tcc_history.history['loss']\n",
        "val_loss = tcc_history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}